{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, warnings, random, datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model\n",
    "import lightgbm as lgb\n",
    "\n",
    "def make_predictions(tr_df, tt_df, features_columns, target, lgb_params, NFOLDS=2):\n",
    "    \n",
    "    folds = GroupKFold(n_splits=NFOLDS)\n",
    "\n",
    "    X,y = tr_df[features_columns], tr_df[target]    \n",
    "    P,P_y = tt_df[features_columns], tt_df[target]  \n",
    "    split_groups = tr_df['DT_M']\n",
    "\n",
    "    tt_df = tt_df[['TransactionID',target]]    \n",
    "    predictions = np.zeros(len(tt_df))\n",
    "    oof = np.zeros(len(tr_df))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=split_groups)):\n",
    "        print('Fold:',fold_)\n",
    "        tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n",
    "        vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n",
    "            \n",
    "        print(len(tr_x),len(vl_x))\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "\n",
    "        estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            valid_sets = [tr_data, vl_data],\n",
    "            verbose_eval = 200,\n",
    "        )   \n",
    "        \n",
    "        pp_p = estimator.predict(P)\n",
    "        predictions += pp_p/NFOLDS\n",
    "        \n",
    "        oof_preds = estimator.predict(vl_x)\n",
    "        oof[val_idx] = (oof_preds - oof_preds.min())/(oof_preds.max() - oof_preds.min())\n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n",
    "            print(feature_imp)\n",
    "        \n",
    "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
    "        gc.collect()\n",
    "        \n",
    "    tt_df['prediction'] = predictions\n",
    "    print('OOF AUC:', metrics.roc_auc_score(y, oof))\n",
    "    #if LOCAL_TEST:\n",
    "        #print('Holdout AUC:', metrics.roc_auc_score(tt_df[TARGET], tt_df['prediction']))\n",
    "    \n",
    "    return tt_df, feature_imp\n",
    "## -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "LOCAL_TEST = False\n",
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':800,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "Shape control: (590540, 791) (506691, 791)\n"
     ]
    }
   ],
   "source": [
    "########################### DATA LOAD\n",
    "#################################################################################\n",
    "print('Load Data')\n",
    "\n",
    "#if LOCAL_TEST:\n",
    "   # train_df = pd.read_pickle('../input/ieee-fe-for-local-test/train_df.pkl')\n",
    "   # test_df = pd.read_pickle('../input/ieee-fe-for-local-test/test_df.pkl') \n",
    "\n",
    "train_df = pd.read_pickle('../data/train_df.pkl')\n",
    "test_df = pd.read_pickle('../data/test_df.pkl')\n",
    "    \n",
    "remove_features = pd.read_pickle('../data/remove_features.pkl')\n",
    "remove_features = list(remove_features.values)\n",
    "print('Shape control:', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1278.41 Mb (41.1% reduction)\n",
      "Mem. usage decreased to 1104.71 Mb (41.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "########################### Final features list\n",
    "features_columns = [col for col in list(train_df) if col not in remove_features]\n",
    "\n",
    "########################### Final Minification\n",
    "## I don't like this part as it changes float numbers\n",
    "## small change but change.\n",
    "## To be able to train lgbm without \n",
    "## minification we need to do some changes on model\n",
    "## we will do it later.\n",
    "if not LOCAL_TEST:\n",
    "    train_df = reduce_mem_usage(train_df)\n",
    "    test_df  = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "453219 137321\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.99996\tvalid_1's auc: 0.908352\n",
      "Early stopping, best iteration is:\n",
      "[287]\ttraining's auc: 0.999965\tvalid_1's auc: 0.909377\n",
      "     Value               Feature\n",
      "0        0       D8_not_same_day\n",
      "1        0             D9_not_na\n",
      "2        0                    V1\n",
      "3        0                  V107\n",
      "4        0                  V113\n",
      "..     ...                   ...\n",
      "767    482     D4_DT_D_std_score\n",
      "768    487  card5_DT_D_hour_dist\n",
      "769    489  card3_DT_D_hour_dist\n",
      "770    565     product_type_DT_W\n",
      "771    591     product_type_DT_D\n",
      "\n",
      "[772 rows x 2 columns]\n",
      "Fold: 1\n",
      "488908 101632\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.935281\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's auc: 0.999939\tvalid_1's auc: 0.936415\n",
      "     Value                        Feature\n",
      "0        0                      D9_not_na\n",
      "1        0                             V1\n",
      "2        0                           V101\n",
      "3        0                           V107\n",
      "4        0                           V112\n",
      "..     ...                            ...\n",
      "767    179              product_type_DT_M\n",
      "768    182  TransactionAmt_DT_D_std_score\n",
      "769    192             D10_DT_D_std_score\n",
      "770    192              product_type_DT_W\n",
      "771    195    TransactionAmt_DT_D_min_max\n",
      "\n",
      "[772 rows x 2 columns]\n",
      "Fold: 2\n",
      "414300 176240\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.999992\tvalid_1's auc: 0.938749\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's auc: 0.999988\tvalid_1's auc: 0.939271\n",
      "     Value             Feature\n",
      "0        0           D9_not_na\n",
      "1        0                  M1\n",
      "2        0                  V1\n",
      "3        0                V103\n",
      "4        0                V107\n",
      "..     ...                 ...\n",
      "767    213         uid4_D2_std\n",
      "768    214   product_type_DT_W\n",
      "769    218   D8_DT_D_std_score\n",
      "770    223   product_type_DT_D\n",
      "771    228  D10_DT_D_std_score\n",
      "\n",
      "[772 rows x 2 columns]\n",
      "Fold: 3\n",
      "415193 175347\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.999976\tvalid_1's auc: 0.93464\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's auc: 0.999957\tvalid_1's auc: 0.935474\n",
      "     Value                      Feature\n",
      "0        0                    D9_not_na\n",
      "1        0                           V1\n",
      "2        0                         V101\n",
      "3        0                         V103\n",
      "4        0                         V107\n",
      "..     ...                          ...\n",
      "767    189  TransactionAmt_DT_D_min_max\n",
      "768    192                  uid4_D2_std\n",
      "769    197            product_type_DT_W\n",
      "770    212            product_type_DT_D\n",
      "771    229           D10_DT_D_std_score\n",
      "\n",
      "[772 rows x 2 columns]\n",
      "OOF AUC: 0.9253545294435901\n",
      "Wall time: 12min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "########################### Model Train\n",
    "if LOCAL_TEST:\n",
    "    lgb_params['learning_rate'] = 0.1\n",
    "    lgb_params['n_estimators'] = 10000\n",
    "    lgb_params['early_stopping_rounds'] = 100\n",
    "    test_predictions, feature_imp = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params, NFOLDS=4)\n",
    "else:\n",
    "    lgb_params['learning_rate'] = 0.007\n",
    "    lgb_params['n_estimators'] = 10000\n",
    "    lgb_params['early_stopping_rounds'] = 100    \n",
    "    test_predictions, feature_imp = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params, NFOLDS=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "\n",
    "test_predictions['isFraud'] = test_predictions['prediction']\n",
    "test_predictions[['TransactionID','isFraud']].to_csv('../result/LGBM_lr0.1_group4fold_OOFAUC_0.9254_lb_0.9425.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
